{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6632358995471387\n",
      "0.6648826677645121\n",
      "0.6479873717442778\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy\n",
    "\n",
    "features2016=pd.read_csv('features2016.csv')\n",
    "count=0\n",
    "for i in range(0,len(features2016.index)):\n",
    "    count = count + features2016.loc[i, 'winner']\n",
    "count=count/len(features2016.index)\n",
    "print(count)\n",
    "\n",
    "count=0\n",
    "for i in range(0,len(features2016.index)):\n",
    "    if(features2016.loc[i, 'TMW']==0):\n",
    "        count = count + features2016.loc[i, 'winner']\n",
    "    if(features2016.loc[i, 'TMW']>0):\n",
    "        count = count + 1\n",
    "        \n",
    "count=count/len(features2016.index)\n",
    "print(count)\n",
    "\n",
    "\n",
    "\n",
    "features2017=pd.read_csv('features2017.csv')\n",
    "count=0\n",
    "for i in range(0,len(features2017.index)):\n",
    "    count = count + features2017.loc[i, 'winner']\n",
    "count=count/len(features2017.index)\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2016 = features2016.filter(['FS','W1SP','W2SP','WSP','DF','BP','COMPLETE','TPW','SERVEADV','winner'], axis=1)\n",
    "features2017 = features2017.filter(['FS','W1SP','W2SP','WSP','DF','BP','COMPLETE','TPW','SERVEADV','winner'], axis=1)\n",
    "\n",
    "\n",
    "X_train = features2016.iloc[:, features2016.columns.get_loc('FS'):features2016.columns.get_loc('SERVEADV')].values\n",
    "y_train = features2016.iloc[:, features2016.columns.get_loc('winner')].values\n",
    "\n",
    "\n",
    "X_test = features2017.iloc[:, features2017.columns.get_loc('FS'):features2017.columns.get_loc('SERVEADV')].values\n",
    "y_test = features2017.iloc[:, features2017.columns.get_loc('winner')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cufar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, kernel_initializer=\"uniform\", activation=\"relu\", input_dim=8)`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\cufar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\users\\cufar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "c:\\users\\cufar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "2429/2429 [==============================] - 3s 1ms/step - loss: 0.6519 - acc: 0.6797\n",
      "Epoch 2/20\n",
      "2429/2429 [==============================] - 0s 155us/step - loss: 0.4060 - acc: 0.8921\n",
      "Epoch 3/20\n",
      "2429/2429 [==============================] - 0s 152us/step - loss: 0.2250 - acc: 0.9300\n",
      "Epoch 4/20\n",
      "2429/2429 [==============================] - 0s 146us/step - loss: 0.1763 - acc: 0.9374\n",
      "Epoch 5/20\n",
      "2429/2429 [==============================] - 0s 148us/step - loss: 0.1625 - acc: 0.9391\n",
      "Epoch 6/20\n",
      "2429/2429 [==============================] - 0s 154us/step - loss: 0.1571 - acc: 0.9378\n",
      "Epoch 7/20\n",
      "2429/2429 [==============================] - 0s 159us/step - loss: 0.1541 - acc: 0.9391\n",
      "Epoch 8/20\n",
      "2429/2429 [==============================] - 0s 164us/step - loss: 0.1531 - acc: 0.9391\n",
      "Epoch 9/20\n",
      "2429/2429 [==============================] - 0s 194us/step - loss: 0.1520 - acc: 0.9395\n",
      "Epoch 10/20\n",
      "2429/2429 [==============================] - 1s 251us/step - loss: 0.1508 - acc: 0.9399\n",
      "Epoch 11/20\n",
      "2429/2429 [==============================] - 0s 167us/step - loss: 0.1500 - acc: 0.9399\n",
      "Epoch 12/20\n",
      "2429/2429 [==============================] - 0s 190us/step - loss: 0.1494 - acc: 0.9403\n",
      "Epoch 13/20\n",
      "2429/2429 [==============================] - 1s 223us/step - loss: 0.1486 - acc: 0.9411\n",
      "Epoch 14/20\n",
      "2429/2429 [==============================] - 0s 152us/step - loss: 0.1481 - acc: 0.9407\n",
      "Epoch 15/20\n",
      "2429/2429 [==============================] - 0s 175us/step - loss: 0.1479 - acc: 0.9424\n",
      "Epoch 16/20\n",
      "2429/2429 [==============================] - 0s 155us/step - loss: 0.1472 - acc: 0.9407\n",
      "Epoch 17/20\n",
      "2429/2429 [==============================] - 0s 198us/step - loss: 0.1464 - acc: 0.9403\n",
      "Epoch 18/20\n",
      "2429/2429 [==============================] - 0s 200us/step - loss: 0.1462 - acc: 0.9407\n",
      "Epoch 19/20\n",
      "2429/2429 [==============================] - 0s 162us/step - loss: 0.1452 - acc: 0.9420\n",
      "Epoch 20/20\n",
      "2429/2429 [==============================] - 0s 154us/step - loss: 0.1449 - acc: 0.9420\n",
      "[[ 787  105]\n",
      " [  73 1569]]\n",
      "0.9297553275453828\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(classifier.summary())\n",
    "\n",
    "# Fitting our model \n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 20)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "\n",
    "# Creating the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cufar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, kernel_initializer=\"uniform\", activation=\"relu\", input_dim=8)`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\cufar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\cufar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 50)                450       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 701\n",
      "Trainable params: 601\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2429 samples, validate on 2534 samples\n",
      "Epoch 1/20\n",
      "2429/2429 [==============================] - 2s 643us/step - loss: 0.2997 - acc: 0.8975 - val_loss: 0.1791 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92739, saving model to Model_Arranco3.h5\n",
      "Epoch 2/20\n",
      "2429/2429 [==============================] - 1s 312us/step - loss: 0.2111 - acc: 0.9205 - val_loss: 0.1728 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/20\n",
      "2429/2429 [==============================] - 1s 269us/step - loss: 0.2028 - acc: 0.9222 - val_loss: 0.1661 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92739 to 0.92897, saving model to Model_Arranco3.h5\n",
      "Epoch 4/20\n",
      "2429/2429 [==============================] - 1s 293us/step - loss: 0.2044 - acc: 0.9210 - val_loss: 0.1617 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92897 to 0.93212, saving model to Model_Arranco3.h5\n",
      "Epoch 5/20\n",
      "2429/2429 [==============================] - 1s 305us/step - loss: 0.1796 - acc: 0.9292 - val_loss: 0.1663 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/20\n",
      "2429/2429 [==============================] - 1s 275us/step - loss: 0.1931 - acc: 0.9304 - val_loss: 0.1698 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/20\n",
      "2429/2429 [==============================] - 1s 321us/step - loss: 0.1935 - acc: 0.9263 - val_loss: 0.1602 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/20\n",
      "2429/2429 [==============================] - 1s 280us/step - loss: 0.1907 - acc: 0.9284 - val_loss: 0.1504 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.93212 to 0.93607, saving model to Model_Arranco3.h5\n",
      "Epoch 9/20\n",
      "2429/2429 [==============================] - 1s 276us/step - loss: 0.1889 - acc: 0.9308 - val_loss: 0.1485 - val_acc: 0.9353\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/20\n",
      "2429/2429 [==============================] - 1s 284us/step - loss: 0.1864 - acc: 0.9325 - val_loss: 0.1523 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/20\n",
      "2429/2429 [==============================] - 1s 274us/step - loss: 0.1865 - acc: 0.9271 - val_loss: 0.1475 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93607 to 0.93804, saving model to Model_Arranco3.h5\n",
      "Epoch 12/20\n",
      "2429/2429 [==============================] - 1s 309us/step - loss: 0.1729 - acc: 0.9428 - val_loss: 0.2044 - val_acc: 0.9112\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/20\n",
      "2429/2429 [==============================] - 1s 305us/step - loss: 0.1793 - acc: 0.9325 - val_loss: 0.1447 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/20\n",
      "2429/2429 [==============================] - 1s 298us/step - loss: 0.1797 - acc: 0.9366 - val_loss: 0.1440 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/20\n",
      "2429/2429 [==============================] - 1s 264us/step - loss: 0.1830 - acc: 0.9329 - val_loss: 0.1847 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/20\n",
      "2429/2429 [==============================] - 1s 316us/step - loss: 0.1863 - acc: 0.9350 - val_loss: 0.1565 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/20\n",
      "2429/2429 [==============================] - 1s 372us/step - loss: 0.1770 - acc: 0.9366 - val_loss: 0.1704 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/20\n",
      "2429/2429 [==============================] - 1s 315us/step - loss: 0.1681 - acc: 0.9354 - val_loss: 0.1411 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/20\n",
      "2429/2429 [==============================] - 1s 281us/step - loss: 0.1697 - acc: 0.9407 - val_loss: 0.1427 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/20\n",
      "2429/2429 [==============================] - 1s 282us/step - loss: 0.1724 - acc: 0.9436 - val_loss: 0.1452 - val_acc: 0.9353\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "[[ 782  110]\n",
      " [  54 1588]]\n",
      "0.9352801894238358\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(classifier.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint('Model_Arranco3.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# Fitting our model \n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 20,validation_data=(X_test, y_test),callbacks=callbacks_list)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Train_Loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e9680b6f45c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train_Loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mLoss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Val_Acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mVal_Acc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train_Acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Train_Loss'"
     ]
    }
   ],
   "source": [
    "with open('Train_Loss', 'rb') as f:\n",
    "    Loss = pickle.load(f)\n",
    "with open('Val_Acc', 'rb') as f:\n",
    "    Val_Acc= pickle.load(f)\n",
    "with open('Train_Acc', 'rb') as f:\n",
    "    Train_Acc = pickle.load(f)\n",
    "with open('Val_Loss', 'rb') as f:\n",
    "    Val_Loss = pickle.load(f)\n",
    "    \n",
    "epochs=40\n",
    "epochs_plot = [i+1 for i in range (epochs)]\n",
    "    \n",
    "plt.figure(1, figsize=(10,5))\n",
    "plt.grid()\n",
    "font = {'size'   : 15}\n",
    "plt.rc('font', **font)\n",
    "plt.title('Trainig loss & Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_plot, Loss, linewidth=4, color='b', label='Training Loss')\n",
    "plt.plot(epochs_plot, Val_Loss, linewidth=4, color='g', label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.figure(2, figsize=(10,5))\n",
    "plt.grid()\n",
    "font = {'size'   : 15}\n",
    "plt.rc('font', **font)\n",
    "plt.title('Traininig Acc & Validation Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_plot, Train_Acc, linewidth=3, color='b', label='Training Accuracy')\n",
    "plt.plot(epochs_plot, Val_Acc, linewidth=3, color='g', label='Validation Accuracy')\n",
    "plt.legend(loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
